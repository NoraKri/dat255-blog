{
  "hash": "03e4ba1d9cea9c8663cbddecc9c2a1dd",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Presentation\"\nauthor: \"Nora Kristiansen, Torjørn Vatnelid\"\ndate: \"2024-04-15\"\ncategories: [code, analysis, llm]\n---\n\nThis is a post with executable code.\n\n::: {#ef362a2a .cell executionInfo='{\"elapsed\":3893,\"status\":\"ok\",\"timestamp\":1711013531109,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=1}\n``` {.python .cell-code}\n%pip install langchain langchain-community langchain-openai unstructured openai pypdf -Uq\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNote: you may need to restart the kernel to use updated packages.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n[notice] A new release of pip is available: 23.0.1 -> 24.0\n[notice] To update, run: pythonw.exe -m pip install --upgrade pip\n```\n:::\n:::\n\n\n::: {#43167ab0 .cell executionInfo='{\"elapsed\":1306,\"status\":\"ok\",\"timestamp\":1711013435174,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=2}\n``` {.python .cell-code}\nfrom langchain.document_loaders import PyPDFLoader, UnstructuredExcelLoader, UnstructuredWordDocumentLoader\n```\n:::\n\n\n::: {#e387a504 .cell execution_count=3}\n``` {.python .cell-code}\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nPERSONAL_API_KEY = os.getenv(\"MY_OPEN_AI_API_KEY\")\n```\n:::\n\n\n::: {#dc429623 .cell executionInfo='{\"elapsed\":2397,\"status\":\"ok\",\"timestamp\":1711013437568,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=4}\n``` {.python .cell-code}\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(openai_api_key=PERSONAL_API_KEY, model=\"gpt-4-0125-preview\")\n```\n:::\n\n\n## Load test documents\n\nDocument loaders\n\n::: {#aee6bdc8 .cell executionInfo='{\"elapsed\":524,\"status\":\"ok\",\"timestamp\":1711013438089,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=5}\n``` {.python .cell-code}\nloader_word = UnstructuredWordDocumentLoader(\"../../content/DPS Kvalifikasjonsgrunnlag - applikasjonsforvaltning V 2.0.docx\")\nloader_pdf = PyPDFLoader(\"../../content/Del-A-Konkurransegrunnlag-aapen-anbudskonkurranse-FOA-del-III xx.pdf\")\nloader_excel = UnstructuredExcelLoader(\"../../content/test.xlsx\")\n```\n:::\n\n\nLoad data from files\n\n::: {#3cea797c .cell executionInfo='{\"elapsed\":5,\"status\":\"ok\",\"timestamp\":1711013438089,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=6}\n``` {.python .cell-code}\ndata_word = loader_word.load()\ndata_pdf = loader_pdf.load()\ndata_excel = loader_excel.load()\n```\n:::\n\n\n::: {#97dce821 .cell execution_count=7}\n``` {.python .cell-code}\nimport re\n\ndef clean_text(text: str):\n    # Remove excessive newlines and keep only ASCII + æøå characters.\n    text = re.sub(r'\\n{2,}', '\\n', text)\n    text = re.sub(r'[^\\x00-\\x7FæøåÆØÅ]+', '', text)\n    # Remove empty strings\n    text = \"\\n\".join([line for line in text.split('\\n') if line.strip() != ''])\n    return text\n```\n:::\n\n\n::: {#daadbb31 .cell executionInfo='{\"elapsed\":3,\"status\":\"ok\",\"timestamp\":1711013566686,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=8}\n``` {.python .cell-code}\nfrom langchain_core.documents import Document\nimport pypdf\n\ndef process_pdf(data) -> Document:\n    \"\"\"\n    Reads a pdf file from the stream, and returns the read text as a Document\n    \"\"\"\n    reader = pypdf.PdfReader(data)\n    text = ''\n    for page_num in range(len(reader.pages)):\n        text += reader.pages[page_num].extract_text()\n    cleaned_text = clean_text(text)\n    doc = Document(page_content=cleaned_text)\n    return doc\n```\n:::\n\n\n::: {#7cd010c9 .cell executionInfo='{\"elapsed\":6,\"status\":\"error\",\"timestamp\":1711013706986,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=9}\n``` {.python .cell-code}\ndoc = process_pdf(\"../../content/Del-A-Konkurransegrunnlag-aapen-anbudskonkurranse-FOA-del-III xx.pdf\")\n```\n:::\n\n\n::: {#4e68e899 .cell executionInfo='{\"elapsed\":4,\"status\":\"ok\",\"timestamp\":1710927452450,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=10}\n``` {.python .cell-code}\nimport csv\ntest_file_name = '../../content/test_file.csv'\nwith open(test_file_name, 'w', newline='') as file:\n    writer = csv.writer(file)\n    writer.writerow(['Column1', 'Column2', 'Column3'])\n    writer.writerow(['Data1', 'Data2', 'Data3'])\n```\n:::\n\n\n::: {#a583b86c .cell executionInfo='{\"elapsed\":2782,\"status\":\"ok\",\"timestamp\":1710928152148,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=11}\n``` {.python .cell-code}\nfrom langchain_community.document_loaders import UnstructuredCSVLoader\nloader_csv = UnstructuredCSVLoader(\"../../content/test_file.csv\")\ndata_csv = loader_csv.load()\n```\n:::\n\n\n::: {#23413a30 .cell executionInfo='{\"elapsed\":302,\"status\":\"ok\",\"timestamp\":1710928160634,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=12}\n``` {.python .cell-code}\ndata_csv\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n[Document(page_content='\\n\\n\\nColumn1\\nColumn2\\nColumn3\\n\\n\\nData1\\nData2\\nData3\\n\\n\\n', metadata={'source': '../../content/test_file.csv'})]\n```\n:::\n:::\n\n\n# Chunk documents\nWe split the documents by tokens\n\n::: {#a25d1a05 .cell executionInfo='{\"elapsed\":301,\"status\":\"ok\",\"timestamp\":1710840992373,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=13}\n``` {.python .cell-code}\nfrom langchain_core.documents import Document\nfrom langchain.text_splitter import TokenTextSplitter\n\n# Take in a document and chunk it if neccessary. Splits on token length.\ndef split_document_by_tokens(document: list[Document], chunk_size: int, overlap: int):\n    splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n    return splitter.split_documents(document)\n```\n:::\n\n\n# Summarize Document(s)\n\n**Dette funker ikke lengre, null peiling hvorfor**\n\nOppsummer ett eller flere dokumenter ved hjelp av map reduction.\n\n1: Map hver chunk til en oppsummering av chunken\n\n2: Reduser alle oppsummeringer til én enkelt oppsummering\n\n::: {#4247f383 .cell execution_count=14}\n``` {.python .cell-code}\nsummary_map_template = \"\"\"Skriv en kortfattet oppsummering av følgende innhold:\n\n{content}\n\nOPPSUMMERING:\n\"\"\"\n\nsummary_reduce_template = \"\"\"Følgende er et sett med oppsummeringer:\n\n{doc_summaries}\n\nLag en sammenhengende oppsumering ut fra disse.\nOPPSUMMERING:\"\"\"\n```\n:::\n\n\n::: {#d4de15bc .cell execution_count=15}\n``` {.python .cell-code}\nfrom langchain.chains import LLMChain, ReduceDocumentsChain, MapReduceDocumentsChain, StuffDocumentsChain\nfrom langchain.prompts import PromptTemplate\n\ndef summarize_document(document: list[Document]):\n    \"\"\"\n    Takes in a list of Documents and summarizes them.\n    :param document: The document(s) to be summarized.\n    :return: A dict of named outputs Dict[str, Any].\n    \"\"\"\n    # Chain to generate a summary from each chunk\n    map_prompt = PromptTemplate.from_template(summary_map_template)\n    map_chain = LLMChain(prompt=map_prompt, llm=llm)\n\n    # Chain to generate one cohesive summary from the summaries\n    reduce_prompt = PromptTemplate.from_template(summary_reduce_template)\n    reduce_chain = LLMChain(prompt=reduce_prompt, llm=llm)\n    stuff_chain = StuffDocumentsChain(llm_chain=reduce_chain, document_variable_name=\"doc_summaries\")\n    reduce_docs_chain = ReduceDocumentsChain(combine_documents_chain=stuff_chain)\n\n    # The complete map reduction chain\n    map_reduce_chain = MapReduceDocumentsChain(\n        llm_chain=map_chain,\n        document_variable_name=\"content\",\n        reduce_documents_chain=reduce_docs_chain\n    )\n\n    splitdocs = split_document_by_tokens(document, 15000, 200)\n    summary = map_reduce_chain.run(splitdocs)\n    return summary\n```\n:::\n\n\n::: {#78e3c115 .cell executionInfo='{\"elapsed\":253,\"status\":\"error\",\"timestamp\":1710160911975,\"user\":{\"displayName\":\"Nora Kristiansen\",\"userId\":4695517471848529000},\"user_tz\":-60}' execution_count=16}\n``` {.python .cell-code}\nsummarized_word = summarize_document(data_pdf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Torva\\IT-Repo\\DAT255-Deep-Learning\\dat255-summarization\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n```\n:::\n:::\n\n\n::: {#7ecf90e1 .cell execution_count=17}\n``` {.python .cell-code}\nsummarized_word\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n'Statens pensjonskasse (SPK) har annonsert en åpen anbudskonkurranse for etablering av en rammeavtale med en lisenspartner for programvareløsninger, med et anslag på verdi mellom 80 til 150 millioner NOK ekskl. mva. over en varighet på 2 år, med mulighet for forlengelse opptil 6 år. Hensikten er å sikre økonomisk fordelaktige og passende avtaler for kjøp og leie av programvarelisenser, inkludert rådgivning og vedlikehold, med fokus på bærekraft og miljøvennlige løsninger. Tilbudsprosessen, som krever elektronisk innsending via Mercell-portalen innen 2. mai 2024, omfatter strenge krav til dokumentasjon og kvalifikasjoner, inkludert økonomisk kapasitet, tekniske og faglige kvalifikasjoner, samt lønns- og arbeidsvilkår i Norge.\\n\\nLeverandører må benytte et elektronisk egenerklæringsskjema (ESPD) for å dokumentere oppfyllelse av kvalifikasjonskravene, med potensial for etterspørsel av ytterligere dokumentasjon av oppdragsgiver. Tildeling av kontrakten baseres på en vurdering av både kvalitative og kvantitative kriterier, gjennomført med en poengmodell som reflekterer kvaliteten på tilbudte produkter eller tjenester, tjenestenivå, klima- og miljøhensyn, samt pris.\\n\\nSPK legger vekt på konfidensialitet og offentlighet i forhold til sensitive opplysninger, og har rett til å avlyse konkurransen om det foreligger saklig grunn. En karensperiode vil bli innført mellom meddelelse om tildeling og kontraktsignering for å sikre en rettferdig og transparent prosess. Dette initiativet følger Lov om offentlige anskaffelser og er designet for å gi alle interesserte leverandører en lik mulighet til å konkurrere på grunnlag av deres kvalifikasjoner og tilbud.'\n```\n:::\n:::\n\n\n",
    "supporting": [
      "presentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}